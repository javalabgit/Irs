# Operating Systems - Key Concepts and Solutions

---

## 1. Conditions for Deadlock & Resource Allocation Graph

**Definition:**  
A deadlock is a situation where a set of processes are blocked because each process holds a resource and waits for another resource held by some other process.

### Necessary Conditions for Deadlock
- **Mutual Exclusion:** At least one resource must be non-shareable.  
- **Hold and Wait:** Processes holding resources wait for others.  
- **No Preemption:** Resources cannot be forcibly taken away.  
- **Circular Wait:** A circular chain of processes each waiting for a resource held by the next.

### Resource Allocation Graph (RAG)
- A directed graph where processes are circles and resources are rectangles.
- **Request Edge:** From process to resource.  
- **Assignment Edge:** From resource to process.

**Deadlock Avoidance Using RAG:**
- System grants resource requests only if the resulting graph has no cycle.
- For single instance resources, cycle detection indicates a deadlock.
- For multiple instances, a cycle is necessary but not sufficient for deadlock.

---

## 2. Techniques to Recover from Deadlocks

| Technique | Advantages | Disadvantages |
|------------|-------------|---------------|
| Abort all deadlocked processes | Simple, guaranteed to break deadlock | Wastes all work done |
| Abort one process at a time | May preserve some work | Repeated checks required |
| Resource Preemption | Can resolve deadlock without aborting processes | Requires rollback, may cause starvation |

- **Preemption** involves taking a resource from one process and giving it to another.  
- **Rollback** may be necessary to restore to a safe state before preemption.

---

## 3. Page Replacement Algorithms: FIFO, LRU

**Reference String:** `70120304230321201701`  
**Number of Frames:** 3

### FIFO Algorithm

| Step | Reference | Frames State | Page Fault? |
|------|------------|--------------|--------------|
| 1 | 7 | [7] | Yes |
| 2 | 0 | [7,0] | Yes |
| 3 | 1 | [7,0,1] | Yes |
| 4 | 2 | [0,1,2] | Yes |
| 5 | 0 | [0,1,2] | No |
| 6 | 3 | [1,2,3] | Yes |
| 7 | 0 | [2,3,0] | Yes |
| 8 | 4 | [3,0,4] | Yes |
| 9 | 2 | [0,4,2] | Yes |
| 10 | 3 | [4,2,3] | Yes |
| 11 | 0 | [2,3,0] | Yes |
| 12 | 3 | [2,3,0] | No |
| 13 | 2 | [2,3,0] | No |
| 14 | 1 | [3,0,1] | Yes |
| 15 | 2 | [0,1,2] | Yes |
| 16 | 0 | [0,1,2] | No |
| 17 | 1 | [0,1,2] | No |
| 18 | 7 | [1,2,7] | Yes |
| 19 | 0 | [2,7,0] | Yes |
| 20 | 1 | [7,0,1] | Yes |

**Total Page Faults:** 15

---

### LRU Algorithm

| Step | Reference | Frames State | Page Fault? |
|------|------------|--------------|--------------|
| 1 | 7 | [7] | Yes |
| 2 | 0 | [7,0] | Yes |
| 3 | 1 | [7,0,1] | Yes |
| 4 | 2 | [0,1,2] | Yes |
| 5 | 0 | [1,2,0] | Yes |
| 6 | 3 | [2,0,3] | Yes |
| 7 | 2 | [0,3,2] | No |
| 8 | 3 | [0,2,3] | No |
| 9 | 0 | [2,3,0] | No |
| 10 | 4 | [3,0,4] | Yes |
| 11 | 2 | [0,4,2] | Yes |
| 12 | 3 | [4,2,3] | Yes |
| 13 | 0 | [2,3,0] | Yes |
| 14 | 3 | [2,0,3] | No |
| 15 | 1 | [0,3,1] | Yes |
| 16 | 2 | [3,1,2] | Yes |
| 17 | 0 | [1,2,0] | Yes |
| 18 | 1 | [2,0,1] | No |
| 19 | 7 | [0,1,7] | Yes |
| 20 | 0 | [1,7,0] | No |
| 21 | 1 | [7,0,1] | No |

**Total Page Faults:** 12

---

## 4. Memory Allocation Techniques

| Technique | Description | Advantages | Disadvantages | Examples |
|------------|--------------|-------------|---------------|-----------|
| Contiguous | Assigns continuous block of memory | Simple, fast access | Internal/external fragmentation | Fixed & variable partitions |
| Paging | Divides memory and processes into fixed pages | Eliminates external fragmentation | Internal fragmentation | Modern OS memory management |
| Segmentation | Divides memory into variable-sized logical segments | Supports modular programming | External fragmentation | Code, stack, heap segments |

---

## 5. File Allocation Techniques

| Technique | Description | Advantages | Disadvantages | Example Use |
|------------|--------------|-------------|---------------|--------------|
| Sequential | Blocks in sequence | Simple, efficient for batch | Poor random access | Text, audio files |
| Linked | Each block points to next | No fragmentation | Slow random access | Log files |
| Indexed | Index block holds pointers | Fast random access | Extra space for index | Databases, large files |

---

## 6. Directory Structures

| Type | Structure | Features |
|-------|------------|-----------|
| Single-level | All files in one directory | Simple, but name clashes possible |
| Two-level | Separate directory for each user | Avoids name conflicts |
| Tree | Hierarchical structure of directories | Scalable, unique pathnames |

---

## 7. Banker's Algorithm

**Definition:**  
A deadlock avoidance algorithm that tests resource allocation states for safety before granting requests.

**Procedure:**  
- Maintain max, allocated, and available resource matrices.  
- Request granted only if resulting state is safe.  
- *Safe* means all processes can finish with available resources in some order.

---

## 8. Disk Scheduling Algorithms

| Algorithm | Description | Advantages | Disadvantages |
|------------|--------------|-------------|---------------|
| SCAN | Head scans back and forth on disk | Reduced seek time | Starvation of some requests |
| C-SCAN | Head moves in one direction only | Uniform wait time | May cause longer wait |
| LOOK | Scan only as far as last request | Saves unnecessary movement | Same as SCAN in worst case |
| C-LOOK | Circular LOOK | Saves movement, fair | Same as C-SCAN |

---

## 9. Access Matrix

- A matrix specifying the rights of each subject over every object.  
- Controls permission and access in OS.

---

## 10. Free Space Management

| Technique | Description | Advantages | Example |
|------------|--------------|-------------|----------|
| Bit Vector | Bits represent free/occupied blocks | Simple, direct | Disk blocks free/used bits |
| Linked List | Free blocks linked in a list | Easy to manage | Linked free blocks on disk |
| Grouping | A block holds address of free blocks | Reduced overhead | Grouped free block addresses |
| Counting | Store start and count of free blocks | Efficient for contiguous frees | Contiguous memory blocks |

---

Absolutely ‚Äî let‚Äôs walk through the **LRU (Least Recently Used)** algorithm **step by step** for your reference string:

---

üìò **Reference String:**
`7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2, 1, 2, 0, 1, 7, 0, 1`

üìó **Number of Frames:** `3`

---

## ‚öôÔ∏è LRU Page Replacement ‚Äî Step-by-Step Explanation

We track which page was used *least recently* to decide which one to replace when a new page is needed and memory is full.

---

| Step | Reference | Frames (Oldest ‚Üí Newest) | Action / Explanation                | Page Fault? |
| ---- | --------- | ------------------------ | ----------------------------------- | ----------- |
| 1    | **7**     | [7]                      | Frame empty ‚Üí load 7                | ‚úÖ           |
| 2    | **0**     | [7, 0]                   | Add 0                               | ‚úÖ           |
| 3    | **1**     | [7, 0, 1]                | Add 1 ‚Üí all 3 frames filled         | ‚úÖ           |
| 4    | **2**     | [0, 1, 2]                | Replace **7** (least recently used) | ‚úÖ           |
| 5    | **0**     | [1, 2, 0]                | 0 used ‚Üí move to most recent        | ‚úÖ           |
| 6    | **3**     | [2, 0, 3]                | Replace **1** (least recently used) | ‚úÖ           |
| 7    | **0**     | [2, 3, 0]                | 0 used again ‚Üí update recency       | ‚ùå           |
| 8    | **4**     | [3, 0, 4]                | Replace **2** (oldest)              | ‚úÖ           |
| 9    | **2**     | [0, 4, 2]                | Replace **3** (least recently used) | ‚úÖ           |
| 10   | **3**     | [4, 2, 3]                | Replace **0**                       | ‚úÖ           |
| 11   | **0**     | [2, 3, 0]                | Replace **4**                       | ‚úÖ           |
| 12   | **3**     | [2, 0, 3]                | 3 already in frame ‚Üí update recency | ‚ùå           |
| 13   | **2**     | [0, 3, 2]                | 2 already in frame ‚Üí update recency | ‚ùå           |
| 14   | **1**     | [3, 2, 1]                | Replace **0** (least recently used) | ‚úÖ           |
| 15   | **2**     | [3, 1, 2]                | 2 already in frame ‚Üí update recency | ‚úÖ           |
| 16   | **0**     | [1, 2, 0]                | Replace **3**                       | ‚úÖ           |
| 17   | **1**     | [2, 0, 1]                | 1 already in frame ‚Üí update recency | ‚ùå           |
| 18   | **7**     | [0, 1, 7]                | Replace **2**                       | ‚úÖ           |
| 19   | **0**     | [1, 7, 0]                | 0 already in frame ‚Üí update recency | ‚ùå           |
| 20   | **1**     | [7, 0, 1]                | 1 already in frame ‚Üí update recency | ‚ùå           |

---

## üßÆ **Total Page Faults = 12**

---

### üß† Key Points About LRU:

* **Page Fault:** Happens when a referenced page is *not* in memory.
* **Replacement Rule:** Replace the page that was *least recently used*.
* **Tracking Recency:** Usually implemented using timestamps or a stack/list of recent page accesses.
* **Advantage:** Approximates the ‚Äúoptimal‚Äù replacement algorithm well.
* **Disadvantage:** Requires hardware or software support to track usage order efficiently.

---

‚úÖ **Final Frames State after step 20:** `[7, 0, 1]`
‚úÖ **Total Page Faults:** **12**

Would you like me to include a visualization (like a timeline or diagram) showing how the frames change with each step?
